{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rwr_reselection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gCFCFG21rZP"
      },
      "source": [
        "!pip install ml_metrics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import heapq \n",
        "import ml_metrics\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import scipy.sparse as sp\n",
        "random.seed(415)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_0sWA2-1uiN"
      },
      "source": [
        "# read in test results\n",
        "test_results = pd.read_csv('test_results_with_personalized_reranking_results_added.csv')\n",
        "test_results = pd.DataFrame(test_results, columns=['userId', 'actual', 'cf_predictions', 'cf_predictions_10','personalized_reranking_predictions'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4URPU7kD7HJ"
      },
      "source": [
        "# read in training data and testing data \n",
        "train_data = pd.read_csv('data_train_set.csv')\n",
        "test_data = pd.read_csv('data_test_set.csv')\n",
        "\n",
        "# combine training and testing data \n",
        "train_test_data = [train_data, test_data]\n",
        "ratings = pd.concat(train_test_data)\n",
        "ratings.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpTT3EPyGF55"
      },
      "source": [
        "# get first n actual predictions for user\n",
        "def get_actual_predictions(user_id, test_results, n):\n",
        "  recommendations= list(map(int, test_results.loc[test_results['userId'] == user_id]['actual'].item()[1:-1].split(\", \")))\n",
        "  recommendations = recommendations[0:n]\n",
        "  return recommendations\n",
        "\n",
        "# get first n recommendations for user\n",
        "def get_users_predictions(user_id, test_results, n):\n",
        "  recommendations =  list(map(int, test_results.loc[test_results['userId'] == user_id]['cf_predictions'].item()[1:-1].split(\", \")))\n",
        "  recommendations = recommendations[0:n]\n",
        "  return recommendations\n",
        "\n",
        "# get first n Personalized Reranking predictions for user\n",
        "def get_pr_predictions(user_id, test_results, n):\n",
        "  recommendations= list(map(int, test_results.loc[test_results['userId'] == user]['personalized_reranking_predictions'].item()[1:-1].split(\", \")))\n",
        "  return recommendations\n",
        "\n",
        "\n",
        "user_id = test_results.userId.unique().tolist()\n",
        "\n",
        "# change baseline predictions from string format into a list\n",
        "cf_predictions_10 =[]\n",
        "for user in user_id:\n",
        "    cf_pred_10 = get_users_predictions(user, test_results, 10)\n",
        "    cf_predictions_10.append(cf_pred_10)\n",
        "\n",
        "test_results['cf_predictions_10'] = cf_predictions_10\n",
        "\n",
        "# change actual predictions from string format into a list\n",
        "actual_predictions = []\n",
        "for user in user_id:\n",
        "    actual_pred = get_actual_predictions(user, test_results, 10)\n",
        "    actual_predictions.append(actual_pred)\n",
        "\n",
        "test_results['actual'] = actual_predictions\n",
        "\n",
        "# change Personalized Reranking predictions from string format into a list\n",
        "pr_predictions=[]\n",
        "for user in user_id:\n",
        "    pr_pred = get_pr_predictions(user, test_results, 10)\n",
        "    pr_predictions.append(pr_pred)\n",
        "\n",
        "test_results['personalized_reranking_predictions'] = pr_predictions\n",
        "\n",
        "test_results=test_results.set_index(\"userId\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Blxtflgqo8hv"
      },
      "source": [
        "# separate movies into short head and long tail data frames\n",
        "df_movies_count_ratings = pd.DataFrame(ratings.groupby('movieId').size(), columns=['count']).reset_index()\n",
        "total_num = len(df_movies_count_ratings)\n",
        "short_head = int(0.2 * total_num)\n",
        "df_short_head = df_movies_count_ratings.nlargest(short_head, 'count')['movieId'].unique()\n",
        "df_long_tail = df_movies_count_ratings.nsmallest(total_num-short_head, 'count')['movieId'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LukL4BD8rjjJ"
      },
      "source": [
        "# create movie tag relevance matrix\n",
        "tagId_filename = 'genome-scores.csv'\n",
        "tags_filename = 'genome-tags.csv'\n",
        "\n",
        "unique_movies = ratings.movieId.unique()\n",
        "df_tag_id = pd.read_csv(tagId_filename, usecols=['movieId', 'tagId', 'relevance'],dtype={'movieId': 'int32','tagId': 'int32', 'relevance': 'float32'})\n",
        "df_tag_id = df_tag_id.loc[df_tag_id['movieId'].isin(unique_movies)]\n",
        "df_tags = pd.read_csv(tags_filename, usecols=['tagId', 'tag'],dtype={'tagId': 'int32', 'tag': 'str'})\n",
        "unique_tag_id = df_tag_id['tagId'].unique().tolist()\n",
        "df_movie_tag_relevance = df_tag_id.pivot(index='movieId', columns='tagId', values='relevance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-67XJ_E5A2O8"
      },
      "source": [
        "df_tag_id.tagId.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mQ_1p86QKPj"
      },
      "source": [
        "# random walk helper function, performs random walk with restart using restart\n",
        "# probability beta until convergence\n",
        "def random_walk(movieId, model, beta):\n",
        "  length = len(model)\n",
        "  r = np.zeros(length)\n",
        "  location = np.where(model.columns == movieId)\n",
        "  r[location] = 1\n",
        "  start = r.copy()\n",
        "  for i in range(10):\n",
        "    r_new = (1-beta)*model@r + (beta)*start\n",
        "    if (np.allclose(r_new, r)):\n",
        "      break\n",
        "    else:\n",
        "      r=r_new\n",
        "  r /= r.sum()\n",
        "  return r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CY_OyE2Gtga"
      },
      "source": [
        "# read in user preference csv\n",
        "df_user_prefs = pd.read_csv(\"user_preferences.csv\")\n",
        "df_user_prefs=df_user_prefs.set_index(\"userId\")\n",
        "user_mean = df_user_prefs['short_head_prefs'].mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JUBV6o62wU1"
      },
      "source": [
        "# random walk with restart with weighted edges (by inner product of two movies and their tags)\n",
        "def rwr_reselection(user, df_tag_id, df_movies_count_ratings, test, df_short_head, df_long_tail, df_movie_tag_relevance, df_user_prefs, user_mean, beta):\n",
        "  # get user recommendations using the user id\n",
        "  user_pref = df_user_prefs.loc[user]['short_head_prefs'].item()\n",
        "  starting_recommendations = list(map(int, test.loc[user]['cf_predictions'][1:-1].split(\", \")))[0:beta]\n",
        "  starting_recommendations = [x for x in starting_recommendations if x in df_movie_tag_relevance.index]\n",
        "\n",
        "  # create transition matrix of probabilities\n",
        "  df_probability = df_movie_tag_relevance.loc[starting_recommendations][:]\n",
        "  df_transpose = df_probability.T\n",
        "  df_probability = df_probability.dot(df_transpose)\n",
        "\n",
        "  # zero diagonal values\n",
        "  np.fill_diagonal(df_probability.values,0)\n",
        "\n",
        "  # normalize all rows so that they sum to 1\n",
        "  sum = df_probability.sum(axis=1).values\n",
        "  df_probability = df_probability.div(sum, axis = 0)\n",
        "\n",
        "  starting_recommendations_first_10 = test.loc[user]['cf_predictions_10']\n",
        "  recommendations = []\n",
        "  new_recs = []\n",
        "  i = 0\n",
        "  \n",
        "  # find all recommendations in first 10 that needs to be reselected\n",
        "  for m in starting_recommendations_first_10:\n",
        "    if (m in df_short_head):\n",
        "      new_recs.append(0)\n",
        "      recommendations.append(i);\n",
        "    else:\n",
        "      new_recs.append(m)\n",
        "    i= i + 1;\n",
        "\n",
        "  # for each recommendation that needs to be reselecteed, perform RWR\n",
        "  for index in recommendations:\n",
        "    target_movie = starting_recommendations_first_10[index]\n",
        "    if (target_movie in df_probability.columns and target_movie in df_short_head):\n",
        "      weights = random_walk(target_movie, df_probability, user_pref)\n",
        "      candidates = df_probability.columns\n",
        "      replacement = np.random.choice(candidates, p=weights, size=1, replace=False)[0]\n",
        "      while (replacement in new_recs):\n",
        "        replacement = np.random.choice(candidates, p=weights, size=1, replace=False)[0]\n",
        "      new_recs[index] = replacement\n",
        "    else:\n",
        "      new_recs[index] = target_movie\n",
        "  return new_recs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrcBeFbq4PgK"
      },
      "source": [
        "# make recommendations using random walk with restart reselection\n",
        "rwr_recs = []\n",
        "count = 0\n",
        "beta = 50\n",
        "for user in user_id:\n",
        "  recs = rwr_reselection(user, df_tag_id, df_movies_count_ratings, test_results, df_short_head, df_long_tail, df_movie_tag_relevance, df_user_prefs, user_mean, beta)\n",
        "  rwr_recs.append(recs)\n",
        "  count = count + 1\n",
        "  print(count, \": \", user)\n",
        "\n",
        "test_results['rwr_predictions'] = rwr_recs\n",
        "actual = list(test_results.actual.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBA-pTv7sRat"
      },
      "source": [
        "test_results['rwr_predictions'] = rwr_recs\n",
        "actual = list(test_results.actual.values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp0v_Vj4-93t"
      },
      "source": [
        "# helper function to calculate prediction coverage\n",
        "def prediction_coverage(predictions, all_items):\n",
        "  predictions = set([j for i in predictions for j in i])\n",
        "  prediction_coverage = len(predictions)/(len(all_items)*1.0)\n",
        "  return prediction_coverage\n",
        "\n",
        "# calculat prediction coverage\n",
        "all_movies = ratings.movieId.unique().tolist()\n",
        "rwr_coverage = prediction_coverage(rwr_recs, all_movies)\n",
        "pr_coverage = prediction_coverage(pr_predictions, all_movies)\n",
        "cf_coverage = prediction_coverage(cf_predictions_10, all_movies)\n",
        "print('rwr: ', rwr_coverage)\n",
        "print('pr: ', pr_coverage)\n",
        "print('cf: ', cf_coverage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ_53u0MJnM_"
      },
      "source": [
        "# calculate long tail coverage\n",
        "def long_tail_coverage(predictions, df_long_tail) :\n",
        "  predictions = set([j for i in predictions for j in i if j in df_long_tail])\n",
        "  prediction_coverage = len(predictions)/(len(df_long_tail)*1.0)\n",
        "  return prediction_coverage\n",
        "\n",
        "\n",
        "rwr_coverage_long_tail = long_tail_coverage(rwr_recs, df_long_tail)\n",
        "pr_coverage_long_tail = long_tail_coverage(pr_predictions, df_long_tail)\n",
        "cf_coverage_long_tail = long_tail_coverage(cf_predictions_10, df_long_tail)\n",
        "print('rwr: ', rwr_coverage_long_tail)\n",
        "print('pr: ', pr_coverage_long_tail)\n",
        "print('cf: ', cf_coverage_long_tail)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa-36Lom_Jy_"
      },
      "source": [
        "# helper function to calculate novelty\n",
        "def novelty(predictions, movie_counts, num_users, len_list):\n",
        "  self_info = []\n",
        "  for l in predictions:\n",
        "    info = 0\n",
        "    for i in l:\n",
        "      info += np.sum(-np.log2(movie_counts[i]/num_users))\n",
        "    self_info.append(info/len_list)\n",
        "  return sum(self_info)/len(predictions)\n",
        "\n",
        "\n",
        "movie_counts = dict(ratings.movieId.value_counts())\n",
        "users = ratings.userId.unique().tolist()\n",
        "rwr_novelty = novelty(rwr_recs, movie_counts, len(user_id), 10)\n",
        "cf_novelty = novelty(cf_predictions_10, movie_counts, len(user_id), 10)\n",
        "pr_novelty = novelty(pr_predictions, movie_counts, len(user_id), 10)\n",
        "print('rwr: ', rwr_novelty)\n",
        "print('pr: ', pr_novelty)\n",
        "print('cf: ', cf_novelty)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgBI1RW6N4KC"
      },
      "source": [
        "# calculate MAP@K\n",
        "rwr_mapk = []\n",
        "for K in np.arange(1, 11):\n",
        "  rwr_mapk.extend([ml_metrics.mapk(actual, rwr_recs, k=K)])\n",
        "print('rwr: ', rwr_mapk)\n",
        "\n",
        "pr_mapk = []\n",
        "for K in np.arange(1, 11):\n",
        "    pr_mapk.extend([ml_metrics.mapk(actual, pr_predictions, k=K)])\n",
        "print('pr: ', pr_mapk)\n",
        "\n",
        "cf_mapk = []\n",
        "for K in np.arange(1, 11):\n",
        "    cf_mapk.extend([ml_metrics.mapk(actual, cf_predictions_10, k=K)])\n",
        "print('cf: ', cf_mapk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hadkeb-QPpIx"
      },
      "source": [
        "# helper function to calculate personalization\n",
        "def personalization(predictions):\n",
        "  # create sparse matrix\n",
        "  sparse_matrix = pd.DataFrame(data=predictions).reset_index().melt(id_vars='index', value_name='movies')\n",
        "  sparse_matrix = pd.notna(sparse_matrix[['index', 'movies']].pivot(index='index', columns='movies', values='movies'))\n",
        "  sparse_matrix = sp.csr_matrix(sparse_matrix.values)\n",
        "\n",
        "  # calculate cosine similarity of upper triangle\n",
        "  similarity = cosine_similarity(X=sparse_matrix, dense_output=False)\n",
        "  upper_triangle = np.triu_indices(similarity.shape[0], k=1)\n",
        "  return 1 - np.mean(similarity[upper_triangle])\n",
        "\n",
        "rwr_personalization = personalization(rwr_recs)\n",
        "pr_personalization = personalization(pr_predictions)\n",
        "cf_personalization = personalization(cf_predictions_10)\n",
        "print('rwr: ', rwr_personalization)\n",
        "print('pr: ', pr_personalization)\n",
        "print('cf: ', cf_personalization)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yas-qBeSQ7nr"
      },
      "source": [
        "# organize movie features\n",
        "rated_movies = ratings.movieId.tolist()\n",
        "movies = pd.read_csv('movies.csv')\n",
        "movies = movies.query('movieId in @rated_movies').set_index(\"movieId\", inplace=False, drop=True)\n",
        "movies = movies.genres.str.split(\"|\", expand=True).reset_index(inplace=False)\n",
        "movies = pd.melt(movies, id_vars='movieId', value_vars=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "movies = movies.drop_duplicates(\"movieId\", inplace=False).set_index('movieId', inplace=False)\n",
        "movies = pd.get_dummies(movies.value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcVIEOnqRlAY"
      },
      "source": [
        "# helper function to calculate intra-list similarity\n",
        "def ils(predictions, movies):\n",
        "  ils = []\n",
        "  for u in range(len(predictions)):\n",
        "    # create sparse matrix\n",
        "    sparse_matrix = movies.loc[predictions[u]]\n",
        "    sparse_matrix = sp.csr_matrix(sparse_matrix.values)\n",
        "    \n",
        "    # calculate cosine similarity\n",
        "    similarity = cosine_similarity(X=sparse_matrix, dense_output=False)\n",
        "    upper_triangle = np.triu_indices(similarity.shape[0], k=1)\n",
        "    ils.append(np.mean(similarity[upper_triangle]))\n",
        "  return np.mean(ils)\n",
        "\n",
        "rwr_similarity = ils(rwr_recs, movies)\n",
        "pr_similarity = ils(pr_predictions, movies)\n",
        "cf_similarity = ils(cf_predictions_10, movies)\n",
        "print('rwr: ', rwr_similarity)\n",
        "print('pr: ', pr_similarity)\n",
        "print('cf: ', cf_similarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIJ3NS7XTQ1B"
      },
      "source": [
        "# helper function to calculate movie category proportion\n",
        "def percent_in_rec(userId, result, movie_cat, test_results):\n",
        "  recs = test_results.loc[userId][result]\n",
        "  recs_long_tail = [x for x in recs if x in movie_cat]\n",
        "  return len(recs_long_tail)/len(recs)\n",
        "\n",
        "# calculate average short-head proportion in recommendation lists\n",
        "avg_short_head = 0;\n",
        "for user in user_id:\n",
        "  avg_short_head += percent_in_rec(user, 'rwr_predictions', df_short_head, test_results)\n",
        "print('rwr: ', avg_short_head/len(user_id))\n",
        "\n",
        "avg_short_head = 0;\n",
        "for user in user_id:\n",
        "  avg_short_head += percent_in_rec(user, 'personalized_reranking_predictions', df_short_head, test_results)\n",
        "print('pr: ', avg_short_head/len(user_id))\n",
        "\n",
        "avg_short_head = 0;\n",
        "for user in user_id:\n",
        "  avg_short_head += percent_in_rec(user, 'cf_predictions_10', df_short_head, test_results)\n",
        "print('cf: ', avg_short_head/len(user_id))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmiGN7hwZHqA"
      },
      "source": [
        "# calculate average long-tail proportion in recommendation lists\n",
        "avg_long_tail = 0;\n",
        "for user in user_id:\n",
        "  avg_long_tail += percent_in_rec(user, 'rwr_predictions', df_long_tail, test_results)\n",
        "print('rwr: ', avg_long_tail/len(user_id))\n",
        "\n",
        "avg_long_tail = 0;\n",
        "for user in user_id:\n",
        "  avg_long_tail += percent_in_rec(user, 'personalized_reranking_predictions', df_long_tail, test_results)\n",
        "print('pr: ', avg_long_tail/len(user_id))\n",
        "\n",
        "avg_long_tail = 0;\n",
        "for user in user_id:\n",
        "  avg_long_tail += percent_in_rec(user, 'cf_predictions_10', df_long_tail, test_results)\n",
        "print('cf: ', avg_long_tail/len(user_id))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}